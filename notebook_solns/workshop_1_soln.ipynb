{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af8637c5-3ccd-4e50-ae8c-2b30d712dba4",
   "metadata": {
    "id": "N8V1VggmZ3JU",
    "tags": []
   },
   "source": [
    "## Set-up: Run the following cell to configure our working directory appropriately.\n",
    "If we are running on Google Colab, the following cell will clone the notebooks into our Colab filespace. If instead running locally, it will add the parent directory of the notebooks to the path such that we can import the custom module ```funcs```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37057c7c-c15e-4d4b-8107-752a4f18b763",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WGyaB2wWWz23",
    "outputId": "f1be5c41-0aa6-45b0-affd-34d1478fa90e"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    !git clone https://github.com/harry-rendell/MLworkshop.git\n",
    "    sys.path.append('./MLworkshop')\n",
    "else:\n",
    "    sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0660b38a",
   "metadata": {
    "id": "a355a31f"
   },
   "source": [
    "## Tips!\n",
    "* In Google Colab you can pass your cursor over a function to see what it does.\n",
    "* If instead you are running locally, you can use Shift+Tab while your cursor is in a function to see what it does."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d294b255",
   "metadata": {
    "id": "c8b3c4ac"
   },
   "source": [
    "# Introduction\n",
    "---\n",
    "We are going to build and train a simple neural network to classify the MNIST dataset. This dataset contains 1,796 grayscale images of handwritten digits from 0 to 9. The images are an 8x8 grid of pixel values. Although this is an easy task for a human, it's not so easy for a computer. Since every image in the database is unique, we need a model which can adapt to different handwriting styles and classify them accurately. This is where machine learning comes in!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84babf1a",
   "metadata": {
    "id": "dcebaeb1"
   },
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Keras imports\n",
    "from tensorflow.python.keras.utils.vis_utils import plot_model\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Input, Dense, Flatten, Reshape, Dropout\n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "# Custom imports\n",
    "from funcs.plotting import plot_classifications, plot_training, plot_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2752d795",
   "metadata": {},
   "source": [
    "# Load in data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84361faa",
   "metadata": {
    "id": "95b9152b"
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "digits = datasets.load_digits()\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(digits.images, digits.target, test_size=0.6, shuffle=True)\n",
    "x_train = x_train/x_train.max() # Normalise data so pixel values are between 0 and 1\n",
    "x_test  = x_test/x_train.max()\n",
    "input_shape  = (8,8)\n",
    "n_classes = 10 # we have 10 different classes, ie 10 integers from 0 to 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61feb97",
   "metadata": {
    "id": "57a4bd6a"
   },
   "source": [
    "# Plot the data\n",
    "---\n",
    "### Let's see what we're working with here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7e096e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 591
    },
    "id": "f149d95f",
    "outputId": "f58d33f3-1405-40de-a015-4f1d1e292540"
   },
   "outputs": [],
   "source": [
    "plot_data(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893fb51e",
   "metadata": {
    "id": "2e27e13a"
   },
   "source": [
    "# Making your model\n",
    "---\n",
    "### This is the basic structure of constructing a dense neural network using Keras\n",
    "> ```\n",
    "> Line 1: i = Input(shape)\n",
    "> Line 2: x = Flatten()(i)\n",
    "> Line 3: x = Dense(n_nodes, activation='relu')(x)\n",
    "> Line 4: x = Dense(n_nodes, activation='relu')(x)\n",
    "> ...\n",
    "> Line 5: o = Dense(n_classes, activation='softmax')(x)\n",
    ">\n",
    "> Line 6: mymodel = Model(i, o, name='My first model!')\n",
    "> Line 7: mymodel.summary()\n",
    "\n",
    "* Line 1: We set the input of the model using the shape of our input. Since we are using 8x8 images in the training data, our input shape is (8,8). You can use the ```input_shape``` parameter defined earlier.\n",
    "* Line 2: This step flattens the 2D input with shape (8,8) into a 1D array with shape (64,), since Dense networks require a 1D input. Note that for every layer we need to pass the previous layer to the current one. Here we do this by putting (i) at the end which passes the input to Flatten().\n",
    "* Line 3: Here we create the first layer. We can choose how many nodes we want in this layer (more nodes = able to model complex data better, but takes longer to train). We also need to set the activation, a sensible choice would be activation='relu'.\n",
    "* Line 4: We can add more layers like this, provided we pass the previous layer to the new layer by putting (x) at the end as before.\n",
    "* Line 5: We define the final ouput layer. The output shape needs to match the shape of the label data (y_train), ie 10. These 10 numbers will correspond to the probability that the input is each of the numbers 0-9. We must use the 'softmax' activation function here as it ensures the probabilities sum to 1.\n",
    "* Line 6: We construct the model using the ```Model()``` function. We pass the input and output. You can also name the model anything you like, e.g. name = 'My first model!'\n",
    "* Line 7: Prints a summary of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b50b2c2",
   "metadata": {
    "id": "69c82300"
   },
   "outputs": [],
   "source": [
    "### Use the template above to make your model here\n",
    "i = Input(shape=input_shape)\n",
    "x = Flatten()(i)\n",
    "x = Dense(30, activation='relu')(x)\n",
    "o = Dense(n_classes, activation='softmax')(x)\n",
    "\n",
    "# Create Model\n",
    "fcc = Model(i, o, name='Dense')\n",
    "fcc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57492c3e",
   "metadata": {
    "id": "271fe6ae"
   },
   "source": [
    "# Training your model\n",
    "---\n",
    "### Now you have defined your model, use the template below to compile and train it.\n",
    "> ```\n",
    "> Line 8: mymodel.compile(...)\n",
    "> Line 9: mymodel_history = mymodel.fit(...)\n",
    "\n",
    "\n",
    "* Line 8: Here we compile the model using ```.compile()```. We need to pass the following: \n",
    "    * optimizer='adam' - a particularly good adaptive optimizer. See https://arxiv.org/abs/1412.6980 if you are interested\n",
    "    * loss='sparse_categorical_crossentropy' - we need to use this loss function for classification tasks\n",
    "    * metrics='accuracy' - ask the model to calculate the accuracy during training\n",
    "\n",
    "\n",
    "* Line 9: Train the model using ```.fit()```. We need to pass a few things here:\n",
    "    * x - training images\n",
    "    * y - training labels\n",
    "    * epochs - how long to train for. ~100 is a good start.\n",
    "    * batch_size - how many images to group up for each training step. ~32 is sensible.\n",
    "    * validation_data - the test images and labels, ie (x_test, y_test).\n",
    "    * verbose - Set this to True if you wish to see the progress of training. Otherwise set to False.\n",
    "    \n",
    "Note, you will need to rerun lines 1-9 if you wish to start training from scratch, as if you only run lines 8 & 9 it will continue where it left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff74c117",
   "metadata": {
    "id": "b141ad12"
   },
   "outputs": [],
   "source": [
    "### Use the template above to compile and fit your model here\n",
    "fcc.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history_fcc = fcc.fit(x=x_train, y=y_train, epochs=100, validation_data=(x_test, y_test), batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532a7067",
   "metadata": {
    "id": "9a0cb20f"
   },
   "source": [
    "# Plot progress of training\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fad093",
   "metadata": {
    "id": "77b018fb"
   },
   "source": [
    "### Now you have defined your model, use the template below to compile and train it.\n",
    "> ```\n",
    "> Line 10: plot_training(...)\n",
    "> Line 11: mymodel.evaluate(...)\n",
    "\n",
    "\n",
    "* Line 10: Pass the output from Line 9 to my custom function plot_training() to see how the training progressed over time.\n",
    "\n",
    "* Line 11: Evaluate the model on the test data to find the final accuracy. Note that this function returns two numbers, loss and accuracy, but we are only interested in the accuracy at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab75ac4c",
   "metadata": {
    "id": "f66dd776"
   },
   "outputs": [],
   "source": [
    "### Use the template above to plot the training of your model, and evaluate the final test accuracy.\n",
    "plot_training(history_fcc)\n",
    "\n",
    "# Calculate accuracy on entire test set\n",
    "_, acc = fcc.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Testing accuracy: {:.1f}%\".format(acc * 100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb06a41",
   "metadata": {
    "id": "77b018fb"
   },
   "source": [
    "# Plot classifications\n",
    "---\n",
    "### Let's plot some of the test data along with the predicted classifcations from the network.\n",
    "> ```\n",
    "> Line 11: predicted = mymodel.predict(x_test).argmax(axis=-1)\n",
    "> Line 12: plot_classifications(x_test, y_test, predicted)\n",
    "\n",
    "\n",
    "* Line 11: Ask the network to predict the labels of the test data. Then choose the one with the highest probability (argmax)\n",
    "\n",
    "* Line 12: Use my custom function to plot a grid of test data with their true and predicted labels. Note, misclassifications will appear in red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db68146b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use the template above to predict and plot the classifications of the test data\n",
    "predicted = fcc.predict(x_test).argmax(axis=-1) \n",
    "plot_classifications(x_test, y_test, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22310bb",
   "metadata": {},
   "source": [
    "# What happens if we train for too long?\n",
    "---\n",
    "### Recompile your model and train your network for longer, what happens to the test accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ad4ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Copy your code corresponding to lines 1-11, then increase epochs (max 500 otherwise it will take too long)\n",
    "i = Input(shape=input_shape)\n",
    "x = Flatten()(i)\n",
    "x = Dense(30, activation='relu')(x)\n",
    "o = Dense(n_classes, activation='softmax')(x)\n",
    "\n",
    "# Create Model\n",
    "fcc = Model(i, o, name='Dense')\n",
    "fcc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f16496",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcc.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history_fcc = fcc.fit(x=x_train, y=y_train, epochs=300, validation_data=(x_test, y_test), batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a97f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training(history_fcc)\n",
    "\n",
    "# Calculate accuracy on entire test set\n",
    "_, train_acc = fcc.evaluate(x_train, y_train, verbose=0)\n",
    "_, test_acc  = fcc.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Training accuracy: {:.1f}%\".format(train_acc * 100.))\n",
    "print(\"Testing accuracy: {:.1f}%\".format(test_acc * 100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ece76b0",
   "metadata": {
    "id": "72f8294c"
   },
   "source": [
    "# Improving test accuracy\n",
    "---\n",
    "### Some techniques we can use to improve test accuracy:\n",
    "* Dropout - During training, a random fraction of nodes are deactivated for each training step. E.g. inserting Dropout(0.1) after a Dense() layer will randomly deactivate 10% of the nodes of that Dense layer, for each training step. This benefits the network as it encourages it to behave like a combination of smaller networks, each of which can continue to work even when some fail to classify. To use dropout, insert the  ```Dropout()``` function after the Dense() layer that you would like to apply the dropout to.\n",
    "* L1/L2 Regularisation - Gradually sets unused weights to zero. You can use the ```l1_l2()``` function and pass it to a Dense layer using ```Dense(..., bias_regularizer=l1_l2() )```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aabae0",
   "metadata": {
    "id": "d36187da"
   },
   "outputs": [],
   "source": [
    "### Copy your code corresponding to lines 1-11, then add Dropout and/or L1/L2 Regularisation \n",
    "from tensorflow.keras.regularizers import l1_l2\n",
    "# Connect input, intermediate, and output layers using the Keras functional API\n",
    "i = Input(shape=input_shape)\n",
    "x = Flatten()(i)\n",
    "x = Dense(50, activation='relu', bias_regularizer=l1_l2())(x)\n",
    "x = Dropout(0.2)(x)\n",
    "o = Dense(n_classes, activation='softmax')(x)\n",
    "\n",
    "\n",
    "# Create Model\n",
    "fcc = Model(i, o, name='Dense')\n",
    "fcc.summary()\n",
    "\n",
    "\n",
    "fcc.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "history_fcc = fcc.fit(x=x_train, y=y_train, epochs=100, validation_data=(x_test, y_test), batch_size=32, verbose=1)\n",
    "\n",
    "plot_training(history_fcc)\n",
    "\n",
    "# Calculate accuracy on entire test set\n",
    "_, train_acc = fcc.evaluate(x_train, y_train, verbose=0)\n",
    "_, test_acc = fcc.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Training accuracy: {:.1f}%\".format(train_acc * 100.))\n",
    "print(\"Testing accuracy: {:.1f}%\".format(test_acc * 100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30208327",
   "metadata": {
    "id": "9f29bc63"
   },
   "source": [
    "# Challenge!\n",
    "### I was able to make a network with a test accuracy 98.1%. Can you do better than this using Dropout and Regularisation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaea8406",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make your best model here!\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "workshop_1_soln.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
