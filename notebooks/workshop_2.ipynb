{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/harry-rendell/MLworkshop/blob/main/notebooks/workshop_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N8V1VggmZ3JU"
   },
   "source": [
    "## Set-up: Run the following cell to configure our working directory appropriately.\n",
    "If we are running on Google Colab, the following cell will clone the notebooks into our Colab filespace. If instead running locally, it will add the parent directory of the notebooks to the path such that we can import the custom module ```funcs```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WGyaB2wWWz23",
    "outputId": "f1be5c41-0aa6-45b0-affd-34d1478fa90e"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'google.colab' in sys.modules:\n",
    "    !git clone https://github.com/harry-rendell/MLworkshop.git\n",
    "    sys.path.append('./MLworkshop')\n",
    "else:\n",
    "    sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a355a31f"
   },
   "source": [
    "## Tips!\n",
    "* In Google Colab you can pass your cursor over a function to see what it does.\n",
    "* If instead you are running locally, you can use Shift+Tab while your cursor is in a function to see what it does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ewL8lGOL_mnN"
   },
   "source": [
    "# Introduction\n",
    "---\n",
    "We are going to build and train a convolutional neural network to classify the MNIST dataset. This dataset contains 60,000 training and 10,000 test images of handwritten digits from 0 to 9. It is a similar dataset to the one used in the first workshop but it is higher resolution, where the images are a 28x28 grid of pixel values. In this notebook we will investigate the following: \n",
    "1. Making and training a simple convolutional network to classify handwritten digits\n",
    "2. Adjusting our network so we can take a look at how it classifies the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2PG0hpYh_mnO"
   },
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# Keras import(s)\n",
    "from tensorflow.python.keras.utils.vis_utils import plot_model\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Input, Dense, Flatten, Reshape, Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "# Custom imports\n",
    "from funcs.plotting import plot_classifications, plot_training, plot_data, plot_latent_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJTgdZsE_mnO"
   },
   "source": [
    "# Load in data\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XFZ4sTP0_mnO"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train/x_train.max() # Normalise data so pixel values are between 0 and 1\n",
    "x_test = x_test/x_test.max()\n",
    "\n",
    "# Add a new axis to the end. This axis is used to specifiy the RGB channel.\n",
    "# Although this axis is unnecessary since we are working with grayscale images, it is required to keep the shapes consistent.\n",
    "x_train = x_train[:,:,:,np.newaxis]\n",
    "x_test  = x_test [:,:,:,np.newaxis]\n",
    "\n",
    "input_shape = (28,28,1)\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6ZO29Ll_mnO"
   },
   "source": [
    "# Plot the data\n",
    "---\n",
    "### Let's take a look at the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tkS0_8ZC_mnP",
    "outputId": "0a90492d-0f40-4e92-889e-f1f53e0e73bb"
   },
   "outputs": [],
   "source": [
    "plot_data(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9xAYFPwD_mnP"
   },
   "source": [
    "# Making your model\n",
    "---\n",
    "### This is the basic structure of constructing a convolutional neural network using Keras\n",
    "> ```\n",
    "> Line 1: i = Input(shape)\n",
    "> Line 2: x = Conv2D(number_of_filters, kernel_size, activation)(i)\n",
    "> Line 3: x = MaxPooling2D(pool_size)(x)\n",
    "> Line 4: x = Conv2D(number_of_filters, kernel_size, activation)(x)\n",
    "> ...\n",
    "> Line 5: x = Flatten()(x)\n",
    "> Line 6: o = Dense(n_classes, activation)(x)\n",
    ">\n",
    "> Line 7: mymodel = Model(i, o, name)\n",
    "> Line 8: mymodel.summary()\n",
    "\n",
    "* Line 1: We set the input of the model using the shape of our input. Since we are using 28x28 images in the training data, our input shape is (28,28). You can use the ```input_shape``` parameter defined earlier.\n",
    "* Line 2: Here we create the first convolutional layer. We need to set the number of filters, kernel_size and activation.\n",
    "* Line 3: Use the MaxPooling2D function which downsamples the image. We don't necessarily need this layer but it helps reduce the size of the network, and therefore speeds up training.\n",
    "* Line 4: We can add more convolutional layers, provided we pass the previous layer to the new layer by putting (x) at the end as before. You may add as many Conv2D/MaxPooling2D layers as you wish after this. However, as both Conv2D/MaxPooling2D reduce the size of the image, you may get an error if you add too many because your output becomes too small!\n",
    "* Line 5: Flatten the output from 2D to 1D so we can use a Dense layer next.\n",
    "* Line 6: We need to finish with a Dense layer rather than a Conv2D layer because the output shape needs to be 1D to match the shape of the label data (y_train), which is also 1D. Also, we need to use an activation which gives a probability for how likely the given input is a particular number, a sensible choice would be activation='softmax' just like in workshop 1.\n",
    "* Line 7: We construct the model using the ```Model()``` function. We pass the input and output. You can also name the model anything you like, e.g. name = 'My first model!'\n",
    "* Line 8: Prints a summary of our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "69c82300"
   },
   "outputs": [],
   "source": [
    "### Use the template above to make your model here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "271fe6ae"
   },
   "source": [
    "# Training your model\n",
    "---\n",
    "### Now you have defined your model, use the template below to compile and train it.\n",
    "> ```\n",
    "> Line 9: mymodel.compile(...)\n",
    "> Line 10: mymodel_history = mymodel.fit(...)\n",
    "\n",
    "\n",
    "* Line 9: Here we compile the model using ```.compile()```. We need to pass the following: \n",
    "    * optimizer='adam'\n",
    "    * loss='sparse_categorical_crossentropy'\n",
    "    * metrics='accuracy'\n",
    "\n",
    "\n",
    "* Line 10: Train the model using ```.fit()```. We need to pass a few things here:\n",
    "    * x - training images\n",
    "    * y - training labels\n",
    "    * epochs - how long to train for. ~10 is a good start.\n",
    "    * batch_size - how many images to group up for each training step. ~128 is sensible.\n",
    "    * validation_data - the test images and labels, ie (x_test, y_test).\n",
    "    * verbose - Set this to True if you wish to see the progress of training. Otherwise set to False.\n",
    "    \n",
    "Note, you will need to rerun lines 1-10 if you wish to start training from scratch, as if you only run lines 9 & 10 it will continue where it left off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f66dd776"
   },
   "outputs": [],
   "source": [
    "### Use the template above to compile and train your model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9a0cb20f"
   },
   "source": [
    "# Plot progress of training\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77b018fb"
   },
   "source": [
    "### Now you have defined your model, use the template below to compile and train it.\n",
    "> ```\n",
    "> Line 11: plot_training(...)\n",
    "> Line 12: mymodel.evaluate(...)\n",
    "\n",
    "\n",
    "* Line 11: Pass the output from Line 9 to my custom function plot_training() to see how the training progressed over time.\n",
    "\n",
    "* Line 12: Evaluate the model on the test data to find the final accuracy. Note that this function returns two numbers, loss and accuracy, but we are only interested in the accuracy at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-J8jpJ1J_mnR"
   },
   "outputs": [],
   "source": [
    "### Use the template above to plot the training and evaluate the test accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DizWTz4i_mnS"
   },
   "source": [
    "# Plot classifications\n",
    "---\n",
    "### Let's plot some of the test data along with the predicted classifcations from the network.\n",
    "> ```\n",
    "> Line 13: predicted = mymodel.predict(x_test).argmax(axis=-1)\n",
    "> Line 14: plot_classifications(x_test, y_test, predicted)\n",
    "\n",
    "\n",
    "* Line 13: Ask the network to predict the labels of the test data. Then choose the one with the highest probability (argmax)\n",
    "\n",
    "* Line 14: Use my custom function to plot a grid of test data with their true and predicted labels. Note, misclassifications will appear in red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tYF8hH2r_mnS"
   },
   "outputs": [],
   "source": [
    "### Use the template above to predict and plot the classifications of the test data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLb1-GX-_mnS"
   },
   "source": [
    "# Let's take a peek inside the network...\n",
    "---\n",
    "Neural networks are often consisdered 'Black Boxes' in the sense that it's incredibly hard to understand how the network is able to make the predictions it does. This is because there are thousands of connections between layers and it is not obvious which connections help classify ones and which classify sixes, for example.\n",
    "\n",
    "However, if we introduce a small Dense layer with only 2 nodes (let's call this the bottle-neck layer), then we can look at the activations of these nodes when we pass different numbers through, and plot them on an x-y plane. Note, a network with a bottle-neck like this is called an autoencoder.\n",
    "\n",
    "To make this network, copy your network from lines 1-10 but this time add a Dense layer with 2 nodes in between lines 5 and 6. Set the activation='None' (this is so that we can have negative outputs since relu only allows positive outputs).\n",
    "\n",
    "You should find that your accuracy goes down when adding this bottle-neck. Why is this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3z2HVg52_mnS"
   },
   "outputs": [],
   "source": [
    "### Copy your code corresponding to lines 1-10, then add a Dense layer described above\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dae8a1a0"
   },
   "source": [
    "# Plotting the activations in the bottle-neck layer\n",
    "---\n",
    "### We will need to define a new model whose output is the Dense(2) layer of the previous model. We can do this using the following:\n",
    "> ```\n",
    "> Line 15: new_model = Model(inputs = mymodel.input, outputs = mymodel.layers[-2].output)\n",
    "> Line 16: latent_output = new_model.predict(x_train)\n",
    "\n",
    "Then we can plot using the following:\n",
    "\n",
    "> ```\n",
    "> Line 17: plot_latent_space(latent_output, y_train, n_classes)\n",
    "\n",
    "Note, we don't need to retrain this new model as it will intiate in the same state as mymodel, which has already been trained!\n",
    "\n",
    "Can you interpret this plot?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fJW0zG60_mnT"
   },
   "outputs": [],
   "source": [
    "### Use the template above to define a new model, find the activations in the Dense(2) layer, and plot it.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "workshop_2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
